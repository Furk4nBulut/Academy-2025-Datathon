{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99039,"databundleVersionId":11820474,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n# Product Price Prediction Project - Jupyter Notebook Version\n\nThis notebook combines all the Python files from your project into a single interactive notebook with the same functionality.\n\"\"\"\n\n# %%\n# Import all required libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom scipy.stats import uniform, randint, loguniform\n\n# Set random seed for reproducibility\nnp.random.seed(42)","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.834312Z","start_time":"2025-05-04T21:45:41.829539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Configuration\n\"\"\"\n# %%\n# Configuration (equivalent to config.py)\nDATASET_PATH = 'dataset/'\nTRAINING_DATA_PATH = DATASET_PATH + \"train.csv\"\nTESTING_DATA_PATH = DATASET_PATH + \"testFeatures.csv\"\n\nLOW_QUANTILE = 0.05\nUP_QUANTILE = 0.95\nCAT_THRESHOLD = 10\nCAR_THRESHOLD = 20\nCORRELATION_THRESHOLD = 0.60\nCAT_LENGTH = 10\nNUM_METHOD = \"median\"","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.897698Z","start_time":"2025-05-04T21:45:41.895586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Helper Functions\n\"\"\"\n# %%\n# Helper functions (equivalent to helpers.py)\ndef check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(3))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(3))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ndef grab_col_names(dataframe, cat_th=CAT_THRESHOLD, car_th=CAR_THRESHOLD):\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtype != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtype == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtype != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, cat_but_car, num_cols\n\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.xticks(rotation=45)\n        plt.savefig(f'{col_name}_countplot.png')\n        plt.close()\n\ndef num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.50, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n    if plot:\n        dataframe[numerical_col].hist(bins=50)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.savefig(f'{numerical_col}_histogram.png')\n        plt.close()\n    print(\"#####################################\")\n\ndef target_summary_with_cat(dataframe, target, categorical_col):\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n\ndef high_correlated_cols(dataframe, plot=False, corr_th=CORRELATION_THRESHOLD):\n    corr = dataframe.corr(numeric_only=True)\n    cor_matrix = corr.abs()\n    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n    if plot:\n        sns.heatmap(corr, cmap=\"RdBu\", annot=True)\n        plt.savefig('correlation_heatmap.png')\n        plt.close()\n    return drop_list\n\ndef outlier_thresholds(dataframe, variable, low_quantile=LOW_QUANTILE, up_quantile=UP_QUANTILE):\n    q1 = dataframe[variable].quantile(low_quantile)\n    q3 = dataframe[variable].quantile(up_quantile)\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    return lower_bound, upper_bound\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    return dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None)\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[dataframe[variable] < low_limit, variable] = low_limit\n    dataframe.loc[dataframe[variable] > up_limit, variable] = up_limit\n    return dataframe\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\n\ndef remove_missing_values(dataframe):\n    print(\"##################### Missing Values Before #####################\")\n    print(dataframe.isnull().sum())\n    dataframe_cleaned = dataframe.dropna()\n    print(\"##################### Missing Values After #####################\")\n    print(dataframe_cleaned.isnull().sum())\n    return dataframe_cleaned\n\ndef quick_missing_imp(data, num_method=NUM_METHOD, cat_length=CAT_LENGTH, target=\"Age\"):\n    variables_with_na = [col for col in data.columns if data[col].isnull().sum() > 0]\n    temp_target = data[target] if target in data.columns else None\n    print(\"# BEFORE\")\n    print(data[variables_with_na].isnull().sum(), \"\\n\")\n    data = data.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= cat_length) else x, axis=0)\n    if num_method == \"mean\":\n        data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n    elif num_method == \"median\":\n        data = data.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\n    if temp_target is not None:\n        data[target] = temp_target\n    print(\"# AFTER\")\n    print(\"Categorical variables filled with mode\")\n    print(f\"Numerical variables filled with {num_method}\")\n    print(data[variables_with_na].isnull().sum(), \"\\n\")\n    return data\n\ndef rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\ndef rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtype == 'O'\n                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() / len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n    return temp_df\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    return pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.956942Z","start_time":"2025-05-04T21:45:41.942706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Data Loading\n\"\"\"\n# %%\n# DataLoader class (equivalent to dataset.py)\nclass DataLoader:\n    def __init__(self, training_data_path, testing_data_path):\n        self.training_data_path = training_data_path\n        self.testing_data_path = testing_data_path\n        print(\"Initializing DataLoader...\")\n\n    def get_data(self):\n        print(\"Loading data...\")\n        # Load and combine data\n        train = pd.read_csv(self.training_data_path)\n        test = pd.read_csv(self.testing_data_path)\n        df = pd.concat([train, test], ignore_index=True)\n        df = df.reset_index(drop=True)\n        print(\"Data loaded successfully.\")\n        return df","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.994405Z","start_time":"2025-05-04T21:45:41.991570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Data Preprocessing\n\"\"\"\n# %%\n# DataPreprocessing class (equivalent to data_preprocessing.py)\nclass DataPreprocessing:\n    def __init__(self, dataframe):\n        \"\"\"\n        Initialize with a combined DataFrame (train + test).\n        \"\"\"\n        self.df = dataframe.copy()\n\n    def preprocess(self, is_test_only=False):\n        \"\"\"\n        Preprocess the data and return train/validation splits or test data.\n        \"\"\"\n        self.handle_outliers()\n        self.handle_missing_values()\n        self.feature_engineering()\n        self.drop_unnecessary_columns()\n        self.encode_features()\n\n        if is_test_only:\n            # Test verisini al ve 'id'yi düşürmeden önce sakla\n            test_data = self.df[self.df['ürün fiyatı'].isnull()].drop('ürün fiyatı', axis=1)\n            test_ids = test_data[\"id\"].copy()  # 'id'yi sakla\n            test_data = test_data.drop(columns=['id'])  # 'id'yi test verisinden çıkar\n            return test_data, test_ids  # 'test_ids' ile birlikte döndür\n        else:\n            # Eğitim verisini al ve 'id'yi düşür\n            train_data = self.df[self.df['ürün fiyatı'].notnull()]\n            train_data = train_data.drop(columns=['id'])  # 'id'yi düşür\n\n            X = train_data.drop('ürün fiyatı', axis=1)\n            y = train_data['ürün fiyatı']\n            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n            return X_train, X_val, y_train, y_val\n\n    def handle_outliers(self):\n        \"\"\"\n        Handle outliers using IQR method for numerical columns (excluding ürün fiyatı).\n        \"\"\"\n        num_cols = self.df.select_dtypes(include=np.number).columns\n        num_cols = [col for col in num_cols if col != 'ürün fiyatı']  # Hedef değişkeni hariç tut\n        for col in num_cols:\n            if check_outlier(self.df, col):\n                self.df = replace_with_thresholds(self.df, col)\n\n    def handle_missing_values(self):\n        \"\"\"\n        Handle missing values: mean for numerical (excluding ürün fiyatı), mode for categorical.\n        \"\"\"\n        num_cols = self.df.select_dtypes(include=np.number).columns\n        num_cols = [col for col in num_cols if col != 'ürün fiyatı']\n        self.df[num_cols] = self.df[num_cols].fillna(self.df[num_cols].mean())\n        cat_cols = self.df.select_dtypes(include='object').columns\n        for col in cat_cols:\n            self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n\n    def feature_engineering(self):\n        \"\"\"\n        Create new features for the dataset.\n        \"\"\"\n        # Besin değeri ile ilgili özellikler\n        self.df['besin_değeri_log'] = np.log1p(self.df['ürün besin değeri'])  # Log dönüşümü\n\n        # Ürün kategorisi bazlı ortalama besin değeri\n        self.df['kategori_ortalama_besin'] = self.df.groupby('ürün kategorisi')['ürün besin değeri'].transform('mean')\n\n    def drop_unnecessary_columns(self):\n        \"\"\"\n        Drop unnecessary columns.\n        \"\"\"\n        columns_to_drop = ['ürün üretim yeri', 'market', 'şehir']  # Tek değerli sütunlar\n        self.df.drop(columns=[col for col in columns_to_drop if col in self.df.columns], inplace=True)\n\n    def encode_features(self):\n        \"\"\"\n        Encode categorical features (ürün, ürün kategorisi).\n        \"\"\"\n        cat_cols, cat_but_car, num_cols = grab_col_names(self.df)\n\n        # Binary veya düşük kardinaliteli sütunlar için label encoding\n        binary_cols = [col for col in cat_cols if self.df[col].nunique() <= 3]  # Örneğin, ürün kategorisi\n        for col in binary_cols:\n            self.df = label_encoder(self.df, col)\n\n        # Yüksek kardinaliteli sütunlar (örneğin, ürün) için target encoding\n        high_cardinality_cols = cat_but_car + [col for col in cat_cols if col not in binary_cols]\n        for col in high_cardinality_cols:\n            if col in self.df.columns:\n                # Train verisi için hedef ortalaması hesapla\n                train_data = self.df[self.df['ürün fiyatı'].notnull()]\n                target_means = train_data.groupby(col)['ürün fiyatı'].mean()\n                # Tüm veriye ortalamaları uygula, bilinmeyen değerler için genel ortalama\n                self.df[col] = self.df[col].map(target_means).fillna(train_data['ürün fiyatı'].mean())\n\n        # Kalan kategorik sütunlar için one-hot encoding\n        remaining_cat_cols = [col for col in cat_cols if col not in binary_cols and col not in high_cardinality_cols]\n        if remaining_cat_cols:\n            self.df = one_hot_encoder(self.df, remaining_cat_cols, drop_first=True)\n\n        # Hala kategorik sütun kalmışsa hata fırlat\n        remaining_object_cols = self.df.select_dtypes(include='object').columns.tolist()\n        if remaining_object_cols:\n            raise ValueError(f\"Categorical columns not fully encoded: {remaining_object_cols}\")","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.056934Z","start_time":"2025-05-04T21:45:42.047719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Hyperparameter Tuning\n\"\"\"\n# %%\n# HyperTuner class (equivalent to HyperTuner.py)\nclass HyperTuner:\n    def __init__(self):\n        \"\"\"\n        Initialize with a dictionary of models and their hyperparameter grids.\n        \"\"\"\n        self.param_grids = {\n            \"LinearRegression\": {},\n            \"Ridge\": {'alpha': [0.1, 1.0, 10.0, 100.0]},\n            \"Lasso\": {'alpha': [0.01, 0.1, 1.0, 10.0]},\n            \"ElasticNet\": {'alpha': [0.01, 0.1, 1.0], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n            \"KNN\": {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']},\n            \"DecisionTree\": {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]},\n            \"RandomForest\": {\n                'n_estimators': randint(60,160),\n                'max_depth': [30, None],\n                'min_samples_split': [5, 10,15],\n                'min_samples_leaf': [1, 2, 4,6]\n            },\n            \"GradientBoosting\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'max_depth': [3, 5, 7],\n                'subsample': uniform(0.6, 0.4),\n                'min_samples_split': [2, 5, 10]\n            },\n            \"XGBoost\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'max_depth': [3, 5, 7, 9],\n                'subsample': uniform(0.6, 0.4),\n                'colsample_bytree': uniform(0.6, 0.4)\n            },\n            \"LightGBM\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'num_leaves': randint(20, 50),\n                'max_depth': [3, 5, 7, -1],\n                'subsample': uniform(0.6, 0.4),\n                'colsample_bytree': uniform(0.6, 0.4)\n            },\n            \"CatBoost\": {\n                'iterations': randint(100, 300),\n                'learning_rate': loguniform(0.005, 0.2),\n                'depth': [4, 6, 8, 10],\n                'l2_leaf_reg': uniform(1, 10),\n                'bagging_temperature': uniform(0, 1)\n            },\n            \"SVR\": {\n                'C': loguniform(0.1, 10),\n                'epsilon': uniform(0.05, 0.2),\n                'kernel': ['rbf', 'linear'],\n                'gamma': loguniform(1e-4, 1e-1)\n            }\n        }\n        self.models = {\n            \"LinearRegression\": LinearRegression(),\n            \"Ridge\": Ridge(),\n            \"Lasso\": Lasso(),\n            \"ElasticNet\": ElasticNet(),\n            \"KNN\": KNeighborsRegressor(),\n            \"DecisionTree\": DecisionTreeRegressor(),\n            \"RandomForest\": RandomForestRegressor(random_state=17),\n            \"GradientBoosting\": GradientBoostingRegressor(random_state=17),\n            \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=17),\n            \"LightGBM\": LGBMRegressor(random_state=17),\n            \"CatBoost\": CatBoostRegressor(silent=True, random_state=17),\n        }\n\n    def tune_model(self, model_name, X, y):\n        \"\"\"\n        Tune the specified model using GridSearchCV or RandomizedSearchCV.\n        \"\"\"\n        if model_name not in self.models:\n            raise ValueError(f\"Model {model_name} not found in models list.\")\n\n        model = self.models[model_name]\n        param_grid = self.param_grids[model_name]\n\n        if param_grid:\n            # Use RandomizedSearchCV for complex models\n            search = RandomizedSearchCV(\n                estimator=model,\n                param_distributions=param_grid,\n                n_iter=2,\n                cv=5,\n                scoring='neg_mean_absolute_error',\n                n_jobs=-1,\n                random_state=42\n            )\n            search.fit(X, y)\n            return search.best_estimator_, search.best_params_\n        else:\n            model.fit(X, y)\n            return model, {}","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.100749Z","start_time":"2025-05-04T21:45:42.093991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Model Evaluation\n\"\"\"\n# %%\n# ModelEvaluator class (equivalent to models.py)\nclass ModelEvaluator:\n    def __init__(self, best_model_name=\"CatBoost\", output_dir=\"predictions/notebook\"):\n        \"\"\"\n        Initialize with a list of regression model names and specify the best model for final predictions.\n        \"\"\"\n        self.model_names = [\n            \"CatBoost\",\n        ]\n        self.best_model_name = best_model_name\n        self.rmse_scores = {}\n        self.mae_scores = {}\n        self.best_params = {}\n        self.tuner = HyperTuner()\n        self.trained_models = {}\n        self.output_dir = output_dir\n        os.makedirs(self.output_dir, exist_ok=True)\n\n    def evaluate_models(self, X, y):\n        \"\"\"\n        Evaluate all models with hyperparameter tuning using 5-fold cross-validation.\n        \"\"\"\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=17)\n\n        print(\"Evaluating models with hyperparameter tuning...\")\n        for name in self.model_names:\n            # Tune and train the model\n            best_model, best_params = self.tuner.tune_model(name, X_train, y_train)\n            self.trained_models[name] = best_model\n            self.best_params[name] = best_params\n\n            # Calculate RMSE\n            rmse = np.mean(np.sqrt(-cross_val_score(best_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n            self.rmse_scores[name] = rmse\n\n            # Calculate MAE\n            mae = np.mean(-cross_val_score(best_model, X, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n            self.mae_scores[name] = mae\n\n            print(f\"RMSE: {round(rmse, 4)} | MAE: {round(mae, 4)} ({name})\")\n            if self.best_params[name]:\n                print(f\"Best parameters: {self.best_params[name]}\")\n\n        # Print the best model based on MAE\n        best_model_mae = min(self.mae_scores, key=self.mae_scores.get)\n        print(f\"\\nBest model based on MAE: {best_model_mae} (MAE: {round(self.mae_scores[best_model_mae], 4)})\")\n        print(f\"Best parameters for {best_model_mae}: {self.best_params[best_model_mae]}\")\n\n        # Print the best model based on RMSE for reference\n        best_model_rmse = min(self.rmse_scores, key=self.rmse_scores.get)\n        print(f\"Best model based on RMSE: {best_model_rmse} (RMSE: {round(self.rmse_scores[best_model_rmse], 4)})\")\n\n        return X_train, X_test, y_train, y_test\n\n    def train_and_predict(self, X_train, y_train, X_test, test_ids, output_file=\"submission.csv\"):\n        \"\"\"\n        Train the best model with optimized parameters and save predictions to CSV.\n\n        Args:\n            X_train (pd.DataFrame): Training features\n            y_train (pd.Series): Training target values\n            X_test (pd.DataFrame): Test features to predict on\n            test_ids (pd.Series): IDs for test samples\n            output_file (str): Output CSV filename\n\n        Returns:\n            np.ndarray: Model predictions\n        \"\"\"\n        # Model training with verbose output\n        print(f\"\\n⏳ Training {self.best_model_name} model...\")\n        start_time = time.time()\n\n        # Hyperparameter tuning and training\n        best_model, best_params = self.tuner.tune_model(self.best_model_name, X_train, y_train)\n        self.best_params[self.best_model_name] = best_params\n\n        # Train final model\n        best_model.fit(X_train, y_train)\n        training_time = time.time() - start_time\n        print(f\"✅ Training completed in {training_time:.2f} seconds\")\n        print(f\"🏆 Best parameters: {best_params}\")\n\n        # Generate predictions - keep as floating point without rounding\n        predictions = best_model.predict(X_test)\n\n        # Create submission DataFrame with floating point prices\n        submission_df = pd.DataFrame({\n            \"id\": test_ids.astype(int),\n            \"ürün fiyatı\": predictions.astype(float)  # Ensure floating point type\n        })\n\n        # Save to CSV without index\n        output_path = os.path.join(self.output_dir, output_file)\n        submission_df.to_csv(output_path, index=False, float_format='%.4f')  # 4 decimal places\n\n        print(f\"\\n📁 Predictions saved to '{output_path}'\")\n        print(f\"Sample predictions:\\n{submission_df.head()}\")\n\n        return predictions\n\n    def get_rmse_scores(self):\n        \"\"\"\n        Return the RMSE scores for all evaluated models.\n        \"\"\"\n        return self.rmse_scores\n\n    def get_mae_scores(self):\n        \"\"\"\n        Return the MAE scores for all evaluated models.\n        \"\"\"\n        return self.mae_scores\n\n    def get_best_params(self):\n        \"\"\"\n        Return the best parameters for all evaluated models.\n        \"\"\"\n        return self.best_params","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.152505Z","start_time":"2025-05-04T21:45:42.144402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Main Execution\n\"\"\"\n# %%\n# Main function (equivalent to main.py)\ndef main():\n    # Initialize timer\n    start_time = time.time()\n\n    print(\"🚀 Starting product price prediction pipeline...\")\n\n    # 1. Data Loading\n    print(\"\\n📂 Loading data...\")\n    data_loader = DataLoader(TRAINING_DATA_PATH, TESTING_DATA_PATH)\n    combined_df = data_loader.get_data()\n    print(f\"✅ Data loaded. Shape: {combined_df.shape}\")\n\n    # 2. Data Preprocessing\n    print(\"\\n🔧 Preprocessing data...\")\n    preprocessor = DataPreprocessing(combined_df)\n\n    # Training/validation split\n    X_train, X_val, y_train, y_val = preprocessor.preprocess()\n    print(f\"✅ Training data prepared. Features: {X_train.shape[1]}, Samples: {X_train.shape[0]}\")\n\n    # Test data preparation\n    X_test_submission, test_ids = preprocessor.preprocess(is_test_only=True)\n    print(f\"✅ Test data prepared. Samples: {X_test_submission.shape[0]}\")\n\n    # 3. Model Evaluation\n    print(\"\\n🧪 Evaluating models...\")\n    evaluator = ModelEvaluator(output_dir=\"predictions\")\n    evaluator.evaluate_models(X_train, y_train)\n\n    # 4. Final Prediction\n    print(\"\\n🔮 Making final predictions...\")\n    predictions = evaluator.train_and_predict(\n        X_train,\n        y_train,\n        X_test_submission,\n        test_ids,\n        output_file=\"submission.csv\"\n    )\n\n    # Pipeline completion\n    total_time = time.time() - start_time\n    print(f\"\\n🎉 Pipeline completed in {total_time:.2f} seconds!\")\n\nif __name__ == \"__main__\":\n    import time\n    main()","metadata":{"jupyter":{"is_executing":true},"ExecuteTime":{"start_time":"2025-05-04T21:45:42.191050Z"}},"outputs":[],"execution_count":null}]}