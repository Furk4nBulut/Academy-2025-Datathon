{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99039,"databundleVersionId":11820474,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n# Product Price Prediction Project - Jupyter Notebook Version\n\nThis notebook combines all the Python files from your project into a single interactive notebook with the same functionality.\n\"\"\"\n\n# %%\n# Import all required libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom scipy.stats import uniform, randint, loguniform\n\n# Set random seed for reproducibility\nnp.random.seed(42)","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.834312Z","start_time":"2025-05-04T21:45:41.829539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Configuration\n\"\"\"\n# %%\n# Configuration (equivalent to config.py)\nDATASET_PATH = 'dataset/'\nTRAINING_DATA_PATH = DATASET_PATH + \"train.csv\"\nTESTING_DATA_PATH = DATASET_PATH + \"testFeatures.csv\"\n\nLOW_QUANTILE = 0.05\nUP_QUANTILE = 0.95\nCAT_THRESHOLD = 10\nCAR_THRESHOLD = 20\nCORRELATION_THRESHOLD = 0.60\nCAT_LENGTH = 10\nNUM_METHOD = \"median\"","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.897698Z","start_time":"2025-05-04T21:45:41.895586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Helper Functions\n\"\"\"\n# %%\n# Helper functions (equivalent to helpers.py)\ndef check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(3))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(3))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ndef grab_col_names(dataframe, cat_th=CAT_THRESHOLD, car_th=CAR_THRESHOLD):\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtype != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtype == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtype != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, cat_but_car, num_cols\n\ndef cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.xticks(rotation=45)\n        plt.savefig(f'{col_name}_countplot.png')\n        plt.close()\n\ndef num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.50, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n    if plot:\n        dataframe[numerical_col].hist(bins=50)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.savefig(f'{numerical_col}_histogram.png')\n        plt.close()\n    print(\"#####################################\")\n\ndef target_summary_with_cat(dataframe, target, categorical_col):\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n\ndef high_correlated_cols(dataframe, plot=False, corr_th=CORRELATION_THRESHOLD):\n    corr = dataframe.corr(numeric_only=True)\n    cor_matrix = corr.abs()\n    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n    if plot:\n        sns.heatmap(corr, cmap=\"RdBu\", annot=True)\n        plt.savefig('correlation_heatmap.png')\n        plt.close()\n    return drop_list\n\ndef outlier_thresholds(dataframe, variable, low_quantile=LOW_QUANTILE, up_quantile=UP_QUANTILE):\n    q1 = dataframe[variable].quantile(low_quantile)\n    q3 = dataframe[variable].quantile(up_quantile)\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    return lower_bound, upper_bound\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    return dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None)\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[dataframe[variable] < low_limit, variable] = low_limit\n    dataframe.loc[dataframe[variable] > up_limit, variable] = up_limit\n    return dataframe\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\n\ndef remove_missing_values(dataframe):\n    print(\"##################### Missing Values Before #####################\")\n    print(dataframe.isnull().sum())\n    dataframe_cleaned = dataframe.dropna()\n    print(\"##################### Missing Values After #####################\")\n    print(dataframe_cleaned.isnull().sum())\n    return dataframe_cleaned\n\ndef quick_missing_imp(data, num_method=NUM_METHOD, cat_length=CAT_LENGTH, target=\"Age\"):\n    variables_with_na = [col for col in data.columns if data[col].isnull().sum() > 0]\n    temp_target = data[target] if target in data.columns else None\n    print(\"# BEFORE\")\n    print(data[variables_with_na].isnull().sum(), \"\\n\")\n    data = data.apply(lambda x: x.fillna(x.mode()[0]) if (x.dtype == \"O\" and len(x.unique()) <= cat_length) else x, axis=0)\n    if num_method == \"mean\":\n        data = data.apply(lambda x: x.fillna(x.mean()) if x.dtype != \"O\" else x, axis=0)\n    elif num_method == \"median\":\n        data = data.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\n    if temp_target is not None:\n        data[target] = temp_target\n    print(\"# AFTER\")\n    print(\"Categorical variables filled with mode\")\n    print(f\"Numerical variables filled with {num_method}\")\n    print(data[variables_with_na].isnull().sum(), \"\\n\")\n    return data\n\ndef rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\ndef rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtype == 'O'\n                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() / len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n    return temp_df\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    return pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.956942Z","start_time":"2025-05-04T21:45:41.942706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Data Loading\n\"\"\"\n# %%\n# DataLoader class (equivalent to dataset.py)\nclass DataLoader:\n    def __init__(self, training_data_path, testing_data_path):\n        self.training_data_path = training_data_path\n        self.testing_data_path = testing_data_path\n        print(\"Initializing DataLoader...\")\n\n    def get_data(self):\n        print(\"Loading data...\")\n        # Load and combine data\n        train = pd.read_csv(self.training_data_path)\n        test = pd.read_csv(self.testing_data_path)\n        df = pd.concat([train, test], ignore_index=True)\n        df = df.reset_index(drop=True)\n        print(\"Data loaded successfully.\")\n        return df","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:41.994405Z","start_time":"2025-05-04T21:45:41.991570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Data Preprocessing\n\"\"\"\n# %%\n# DataPreprocessing class (equivalent to data_preprocessing.py)\nclass DataPreprocessing:\n    def __init__(self, dataframe):\n        \"\"\"\n        Initialize with a combined DataFrame (train + test).\n        \"\"\"\n        self.df = dataframe.copy()\n\n    def preprocess(self, is_test_only=False):\n        \"\"\"\n        Preprocess the data and return train/validation splits or test data.\n        \"\"\"\n        self.handle_outliers()\n        self.handle_missing_values()\n        self.feature_engineering()\n        self.drop_unnecessary_columns()\n        self.encode_features()\n\n        if is_test_only:\n            # Test verisini al ve 'id'yi dÃ¼ÅŸÃ¼rmeden Ã¶nce sakla\n            test_data = self.df[self.df['Ã¼rÃ¼n fiyatÄ±'].isnull()].drop('Ã¼rÃ¼n fiyatÄ±', axis=1)\n            test_ids = test_data[\"id\"].copy()  # 'id'yi sakla\n            test_data = test_data.drop(columns=['id'])  # 'id'yi test verisinden Ã§Ä±kar\n            return test_data, test_ids  # 'test_ids' ile birlikte dÃ¶ndÃ¼r\n        else:\n            # EÄŸitim verisini al ve 'id'yi dÃ¼ÅŸÃ¼r\n            train_data = self.df[self.df['Ã¼rÃ¼n fiyatÄ±'].notnull()]\n            train_data = train_data.drop(columns=['id'])  # 'id'yi dÃ¼ÅŸÃ¼r\n\n            X = train_data.drop('Ã¼rÃ¼n fiyatÄ±', axis=1)\n            y = train_data['Ã¼rÃ¼n fiyatÄ±']\n            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n            return X_train, X_val, y_train, y_val\n\n    def handle_outliers(self):\n        \"\"\"\n        Handle outliers using IQR method for numerical columns (excluding Ã¼rÃ¼n fiyatÄ±).\n        \"\"\"\n        num_cols = self.df.select_dtypes(include=np.number).columns\n        num_cols = [col for col in num_cols if col != 'Ã¼rÃ¼n fiyatÄ±']  # Hedef deÄŸiÅŸkeni hariÃ§ tut\n        for col in num_cols:\n            if check_outlier(self.df, col):\n                self.df = replace_with_thresholds(self.df, col)\n\n    def handle_missing_values(self):\n        \"\"\"\n        Handle missing values: mean for numerical (excluding Ã¼rÃ¼n fiyatÄ±), mode for categorical.\n        \"\"\"\n        num_cols = self.df.select_dtypes(include=np.number).columns\n        num_cols = [col for col in num_cols if col != 'Ã¼rÃ¼n fiyatÄ±']\n        self.df[num_cols] = self.df[num_cols].fillna(self.df[num_cols].mean())\n        cat_cols = self.df.select_dtypes(include='object').columns\n        for col in cat_cols:\n            self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n\n    def feature_engineering(self):\n        \"\"\"\n        Create new features for the dataset.\n        \"\"\"\n        # Besin deÄŸeri ile ilgili Ã¶zellikler\n        self.df['besin_deÄŸeri_log'] = np.log1p(self.df['Ã¼rÃ¼n besin deÄŸeri'])  # Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼\n\n        # ÃœrÃ¼n kategorisi bazlÄ± ortalama besin deÄŸeri\n        self.df['kategori_ortalama_besin'] = self.df.groupby('Ã¼rÃ¼n kategorisi')['Ã¼rÃ¼n besin deÄŸeri'].transform('mean')\n\n    def drop_unnecessary_columns(self):\n        \"\"\"\n        Drop unnecessary columns.\n        \"\"\"\n        columns_to_drop = ['Ã¼rÃ¼n Ã¼retim yeri', 'market', 'ÅŸehir']  # Tek deÄŸerli sÃ¼tunlar\n        self.df.drop(columns=[col for col in columns_to_drop if col in self.df.columns], inplace=True)\n\n    def encode_features(self):\n        \"\"\"\n        Encode categorical features (Ã¼rÃ¼n, Ã¼rÃ¼n kategorisi).\n        \"\"\"\n        cat_cols, cat_but_car, num_cols = grab_col_names(self.df)\n\n        # Binary veya dÃ¼ÅŸÃ¼k kardinaliteli sÃ¼tunlar iÃ§in label encoding\n        binary_cols = [col for col in cat_cols if self.df[col].nunique() <= 3]  # Ã–rneÄŸin, Ã¼rÃ¼n kategorisi\n        for col in binary_cols:\n            self.df = label_encoder(self.df, col)\n\n        # YÃ¼ksek kardinaliteli sÃ¼tunlar (Ã¶rneÄŸin, Ã¼rÃ¼n) iÃ§in target encoding\n        high_cardinality_cols = cat_but_car + [col for col in cat_cols if col not in binary_cols]\n        for col in high_cardinality_cols:\n            if col in self.df.columns:\n                # Train verisi iÃ§in hedef ortalamasÄ± hesapla\n                train_data = self.df[self.df['Ã¼rÃ¼n fiyatÄ±'].notnull()]\n                target_means = train_data.groupby(col)['Ã¼rÃ¼n fiyatÄ±'].mean()\n                # TÃ¼m veriye ortalamalarÄ± uygula, bilinmeyen deÄŸerler iÃ§in genel ortalama\n                self.df[col] = self.df[col].map(target_means).fillna(train_data['Ã¼rÃ¼n fiyatÄ±'].mean())\n\n        # Kalan kategorik sÃ¼tunlar iÃ§in one-hot encoding\n        remaining_cat_cols = [col for col in cat_cols if col not in binary_cols and col not in high_cardinality_cols]\n        if remaining_cat_cols:\n            self.df = one_hot_encoder(self.df, remaining_cat_cols, drop_first=True)\n\n        # Hala kategorik sÃ¼tun kalmÄ±ÅŸsa hata fÄ±rlat\n        remaining_object_cols = self.df.select_dtypes(include='object').columns.tolist()\n        if remaining_object_cols:\n            raise ValueError(f\"Categorical columns not fully encoded: {remaining_object_cols}\")","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.056934Z","start_time":"2025-05-04T21:45:42.047719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Hyperparameter Tuning\n\"\"\"\n# %%\n# HyperTuner class (equivalent to HyperTuner.py)\nclass HyperTuner:\n    def __init__(self):\n        \"\"\"\n        Initialize with a dictionary of models and their hyperparameter grids.\n        \"\"\"\n        self.param_grids = {\n            \"LinearRegression\": {},\n            \"Ridge\": {'alpha': [0.1, 1.0, 10.0, 100.0]},\n            \"Lasso\": {'alpha': [0.01, 0.1, 1.0, 10.0]},\n            \"ElasticNet\": {'alpha': [0.01, 0.1, 1.0], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n            \"KNN\": {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']},\n            \"DecisionTree\": {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]},\n            \"RandomForest\": {\n                'n_estimators': randint(60,160),\n                'max_depth': [30, None],\n                'min_samples_split': [5, 10,15],\n                'min_samples_leaf': [1, 2, 4,6]\n            },\n            \"GradientBoosting\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'max_depth': [3, 5, 7],\n                'subsample': uniform(0.6, 0.4),\n                'min_samples_split': [2, 5, 10]\n            },\n            \"XGBoost\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'max_depth': [3, 5, 7, 9],\n                'subsample': uniform(0.6, 0.4),\n                'colsample_bytree': uniform(0.6, 0.4)\n            },\n            \"LightGBM\": {\n                'n_estimators': randint(50, 200),\n                'learning_rate': loguniform(0.005, 0.2),\n                'num_leaves': randint(20, 50),\n                'max_depth': [3, 5, 7, -1],\n                'subsample': uniform(0.6, 0.4),\n                'colsample_bytree': uniform(0.6, 0.4)\n            },\n            \"CatBoost\": {\n                'iterations': randint(100, 300),\n                'learning_rate': loguniform(0.005, 0.2),\n                'depth': [4, 6, 8, 10],\n                'l2_leaf_reg': uniform(1, 10),\n                'bagging_temperature': uniform(0, 1)\n            },\n            \"SVR\": {\n                'C': loguniform(0.1, 10),\n                'epsilon': uniform(0.05, 0.2),\n                'kernel': ['rbf', 'linear'],\n                'gamma': loguniform(1e-4, 1e-1)\n            }\n        }\n        self.models = {\n            \"LinearRegression\": LinearRegression(),\n            \"Ridge\": Ridge(),\n            \"Lasso\": Lasso(),\n            \"ElasticNet\": ElasticNet(),\n            \"KNN\": KNeighborsRegressor(),\n            \"DecisionTree\": DecisionTreeRegressor(),\n            \"RandomForest\": RandomForestRegressor(random_state=17),\n            \"GradientBoosting\": GradientBoostingRegressor(random_state=17),\n            \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=17),\n            \"LightGBM\": LGBMRegressor(random_state=17),\n            \"CatBoost\": CatBoostRegressor(silent=True, random_state=17),\n        }\n\n    def tune_model(self, model_name, X, y):\n        \"\"\"\n        Tune the specified model using GridSearchCV or RandomizedSearchCV.\n        \"\"\"\n        if model_name not in self.models:\n            raise ValueError(f\"Model {model_name} not found in models list.\")\n\n        model = self.models[model_name]\n        param_grid = self.param_grids[model_name]\n\n        if param_grid:\n            # Use RandomizedSearchCV for complex models\n            search = RandomizedSearchCV(\n                estimator=model,\n                param_distributions=param_grid,\n                n_iter=2,\n                cv=5,\n                scoring='neg_mean_absolute_error',\n                n_jobs=-1,\n                random_state=42\n            )\n            search.fit(X, y)\n            return search.best_estimator_, search.best_params_\n        else:\n            model.fit(X, y)\n            return model, {}","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.100749Z","start_time":"2025-05-04T21:45:42.093991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Model Evaluation\n\"\"\"\n# %%\n# ModelEvaluator class (equivalent to models.py)\nclass ModelEvaluator:\n    def __init__(self, best_model_name=\"CatBoost\", output_dir=\"predictions/notebook\"):\n        \"\"\"\n        Initialize with a list of regression model names and specify the best model for final predictions.\n        \"\"\"\n        self.model_names = [\n            \"CatBoost\",\n        ]\n        self.best_model_name = best_model_name\n        self.rmse_scores = {}\n        self.mae_scores = {}\n        self.best_params = {}\n        self.tuner = HyperTuner()\n        self.trained_models = {}\n        self.output_dir = output_dir\n        os.makedirs(self.output_dir, exist_ok=True)\n\n    def evaluate_models(self, X, y):\n        \"\"\"\n        Evaluate all models with hyperparameter tuning using 5-fold cross-validation.\n        \"\"\"\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=17)\n\n        print(\"Evaluating models with hyperparameter tuning...\")\n        for name in self.model_names:\n            # Tune and train the model\n            best_model, best_params = self.tuner.tune_model(name, X_train, y_train)\n            self.trained_models[name] = best_model\n            self.best_params[name] = best_params\n\n            # Calculate RMSE\n            rmse = np.mean(np.sqrt(-cross_val_score(best_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n            self.rmse_scores[name] = rmse\n\n            # Calculate MAE\n            mae = np.mean(-cross_val_score(best_model, X, y, cv=5, scoring=\"neg_mean_absolute_error\"))\n            self.mae_scores[name] = mae\n\n            print(f\"RMSE: {round(rmse, 4)} | MAE: {round(mae, 4)} ({name})\")\n            if self.best_params[name]:\n                print(f\"Best parameters: {self.best_params[name]}\")\n\n        # Print the best model based on MAE\n        best_model_mae = min(self.mae_scores, key=self.mae_scores.get)\n        print(f\"\\nBest model based on MAE: {best_model_mae} (MAE: {round(self.mae_scores[best_model_mae], 4)})\")\n        print(f\"Best parameters for {best_model_mae}: {self.best_params[best_model_mae]}\")\n\n        # Print the best model based on RMSE for reference\n        best_model_rmse = min(self.rmse_scores, key=self.rmse_scores.get)\n        print(f\"Best model based on RMSE: {best_model_rmse} (RMSE: {round(self.rmse_scores[best_model_rmse], 4)})\")\n\n        return X_train, X_test, y_train, y_test\n\n    def train_and_predict(self, X_train, y_train, X_test, test_ids, output_file=\"submission.csv\"):\n        \"\"\"\n        Train the best model with optimized parameters and save predictions to CSV.\n\n        Args:\n            X_train (pd.DataFrame): Training features\n            y_train (pd.Series): Training target values\n            X_test (pd.DataFrame): Test features to predict on\n            test_ids (pd.Series): IDs for test samples\n            output_file (str): Output CSV filename\n\n        Returns:\n            np.ndarray: Model predictions\n        \"\"\"\n        # Model training with verbose output\n        print(f\"\\nâ³ Training {self.best_model_name} model...\")\n        start_time = time.time()\n\n        # Hyperparameter tuning and training\n        best_model, best_params = self.tuner.tune_model(self.best_model_name, X_train, y_train)\n        self.best_params[self.best_model_name] = best_params\n\n        # Train final model\n        best_model.fit(X_train, y_train)\n        training_time = time.time() - start_time\n        print(f\"âœ… Training completed in {training_time:.2f} seconds\")\n        print(f\"ðŸ† Best parameters: {best_params}\")\n\n        # Generate predictions - keep as floating point without rounding\n        predictions = best_model.predict(X_test)\n\n        # Create submission DataFrame with floating point prices\n        submission_df = pd.DataFrame({\n            \"id\": test_ids.astype(int),\n            \"Ã¼rÃ¼n fiyatÄ±\": predictions.astype(float)  # Ensure floating point type\n        })\n\n        # Save to CSV without index\n        output_path = os.path.join(self.output_dir, output_file)\n        submission_df.to_csv(output_path, index=False, float_format='%.4f')  # 4 decimal places\n\n        print(f\"\\nðŸ“ Predictions saved to '{output_path}'\")\n        print(f\"Sample predictions:\\n{submission_df.head()}\")\n\n        return predictions\n\n    def get_rmse_scores(self):\n        \"\"\"\n        Return the RMSE scores for all evaluated models.\n        \"\"\"\n        return self.rmse_scores\n\n    def get_mae_scores(self):\n        \"\"\"\n        Return the MAE scores for all evaluated models.\n        \"\"\"\n        return self.mae_scores\n\n    def get_best_params(self):\n        \"\"\"\n        Return the best parameters for all evaluated models.\n        \"\"\"\n        return self.best_params","metadata":{"ExecuteTime":{"end_time":"2025-05-04T21:45:42.152505Z","start_time":"2025-05-04T21:45:42.144402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n## Main Execution\n\"\"\"\n# %%\n# Main function (equivalent to main.py)\ndef main():\n    # Initialize timer\n    start_time = time.time()\n\n    print(\"ðŸš€ Starting product price prediction pipeline...\")\n\n    # 1. Data Loading\n    print(\"\\nðŸ“‚ Loading data...\")\n    data_loader = DataLoader(TRAINING_DATA_PATH, TESTING_DATA_PATH)\n    combined_df = data_loader.get_data()\n    print(f\"âœ… Data loaded. Shape: {combined_df.shape}\")\n\n    # 2. Data Preprocessing\n    print(\"\\nðŸ”§ Preprocessing data...\")\n    preprocessor = DataPreprocessing(combined_df)\n\n    # Training/validation split\n    X_train, X_val, y_train, y_val = preprocessor.preprocess()\n    print(f\"âœ… Training data prepared. Features: {X_train.shape[1]}, Samples: {X_train.shape[0]}\")\n\n    # Test data preparation\n    X_test_submission, test_ids = preprocessor.preprocess(is_test_only=True)\n    print(f\"âœ… Test data prepared. Samples: {X_test_submission.shape[0]}\")\n\n    # 3. Model Evaluation\n    print(\"\\nðŸ§ª Evaluating models...\")\n    evaluator = ModelEvaluator(output_dir=\"predictions\")\n    evaluator.evaluate_models(X_train, y_train)\n\n    # 4. Final Prediction\n    print(\"\\nðŸ”® Making final predictions...\")\n    predictions = evaluator.train_and_predict(\n        X_train,\n        y_train,\n        X_test_submission,\n        test_ids,\n        output_file=\"submission.csv\"\n    )\n\n    # Pipeline completion\n    total_time = time.time() - start_time\n    print(f\"\\nðŸŽ‰ Pipeline completed in {total_time:.2f} seconds!\")\n\nif __name__ == \"__main__\":\n    import time\n    main()","metadata":{"jupyter":{"is_executing":true},"ExecuteTime":{"start_time":"2025-05-04T21:45:42.191050Z"}},"outputs":[],"execution_count":null}]}