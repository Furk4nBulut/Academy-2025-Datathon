{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# Product Price Prediction Project - LazyPredict Version\n",
    "\n",
    "This notebook uses LazyPredict for quick model evaluation before focusing on the best performing models.\n",
    "\"\"\""
   ],
   "id": "32003f3416af81fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ],
   "id": "161ddfcdc39b3e91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Configuration\n",
    "\"\"\"\n",
    "# %%\n",
    "# Configuration\n",
    "DATASET_PATH = 'dataset/'\n",
    "TRAINING_DATA_PATH = DATASET_PATH + \"train.csv\"\n",
    "TESTING_DATA_PATH = DATASET_PATH + \"testFeatures.csv\"\n",
    "\n",
    "CAT_THRESHOLD = 5\n",
    "CAR_THRESHOLD = 20\n",
    "NUM_METHOD = \"median\""
   ],
   "id": "27d28bcc5f313738"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Helper Functions\n",
    "\"\"\"\n",
    "# %%\n",
    "# Helper functions\n",
    "def grab_col_names(dataframe, cat_th=CAT_THRESHOLD, car_th=CAR_THRESHOLD):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtype != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtype == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtype != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    return cat_cols, cat_but_car, num_cols\n",
    "\n",
    "def label_encoder(dataframe, binary_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe\n",
    "\n",
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    return pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)"
   ],
   "id": "35cedb7f29e8206f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Data Loading\n",
    "\"\"\"\n",
    "# %%\n",
    "# DataLoader class\n",
    "class DataLoader:\n",
    "    def __init__(self, training_data_path, testing_data_path):\n",
    "        self.training_data_path = training_data_path\n",
    "        self.testing_data_path = testing_data_path\n",
    "        print(\"Initializing DataLoader...\")\n",
    "\n",
    "    def get_data(self):\n",
    "        print(\"Loading data...\")\n",
    "        # Load and combine data\n",
    "        train = pd.read_csv(self.training_data_path)\n",
    "        test = pd.read_csv(self.testing_data_path)\n",
    "        df = pd.concat([train, test], ignore_index=True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return df"
   ],
   "id": "41c6529231f3ebf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Data Preprocessing\n",
    "\"\"\"\n",
    "# %%\n",
    "# DataPreprocessing class\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe.copy()\n",
    "\n",
    "    def preprocess(self, is_test_only=False):\n",
    "        self.handle_missing_values()\n",
    "        self.feature_engineering()\n",
    "        self.drop_unnecessary_columns()\n",
    "        self.encode_features()\n",
    "\n",
    "        if is_test_only:\n",
    "            test_data = self.df[self.df['√ºr√ºn fiyatƒ±'].isnull()].drop('√ºr√ºn fiyatƒ±', axis=1)\n",
    "            test_ids = test_data[\"id\"].copy()\n",
    "            test_data = test_data.drop(columns=['id'])\n",
    "            return test_data, test_ids\n",
    "        else:\n",
    "            train_data = self.df[self.df['√ºr√ºn fiyatƒ±'].notnull()]\n",
    "            train_data = train_data.drop(columns=['id'])\n",
    "\n",
    "            X = train_data.drop('√ºr√ºn fiyatƒ±', axis=1)\n",
    "            y = train_data['√ºr√ºn fiyatƒ±']\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "            return X_train, X_val, y_train, y_val\n",
    "\n",
    "    def handle_missing_values(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        num_cols = [col for col in num_cols if col != '√ºr√ºn fiyatƒ±']\n",
    "        self.df[num_cols] = self.df[num_cols].fillna(self.df[num_cols].median())\n",
    "        \n",
    "        cat_cols = self.df.select_dtypes(include='object').columns\n",
    "        for col in cat_cols:\n",
    "            self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "\n",
    "    def feature_engineering(self):\n",
    "        self.df['besin_deƒüeri_log'] = np.log1p(self.df['√ºr√ºn besin deƒüeri'])\n",
    "        self.df['kategori_ortalama_besin'] = self.df.groupby('√ºr√ºn kategorisi')['√ºr√ºn besin deƒüeri'].transform('mean')\n",
    "\n",
    "    def drop_unnecessary_columns(self):\n",
    "        columns_to_drop = ['√ºr√ºn √ºretim yeri', 'market', '≈üehir']\n",
    "        self.df.drop(columns=[col for col in columns_to_drop if col in self.df.columns], inplace=True)\n",
    "\n",
    "    def encode_features(self):\n",
    "        cat_cols, cat_but_car, num_cols = grab_col_names(self.df)\n",
    "\n",
    "        # Binary or low cardinality columns\n",
    "        binary_cols = [col for col in cat_cols if self.df[col].nunique() <= 3]\n",
    "        for col in binary_cols:\n",
    "            self.df = label_encoder(self.df, col)\n",
    "\n",
    "        # High cardinality columns\n",
    "        high_cardinality_cols = cat_but_car + [col for col in cat_cols if col not in binary_cols]\n",
    "        for col in high_cardinality_cols:\n",
    "            if col in self.df.columns:\n",
    "                train_data = self.df[self.df['√ºr√ºn fiyatƒ±'].notnull()]\n",
    "                target_means = train_data.groupby(col)['√ºr√ºn fiyatƒ±'].mean()\n",
    "                self.df[col] = self.df[col].map(target_means).fillna(train_data['√ºr√ºn fiyatƒ±'].mean())\n",
    "\n",
    "        # One-hot encoding for remaining categorical columns\n",
    "        remaining_cat_cols = [col for col in cat_cols if col not in binary_cols and col not in high_cardinality_cols]\n",
    "        if remaining_cat_cols:\n",
    "            self.df = one_hot_encoder(self.df, remaining_cat_cols, drop_first=True)\n",
    "\n",
    "        # Check for remaining categorical columns\n",
    "        remaining_object_cols = self.df.select_dtypes(include='object').columns.tolist()\n",
    "        if remaining_object_cols:\n",
    "            raise ValueError(f\"Categorical columns not fully encoded: {remaining_object_cols}\")"
   ],
   "id": "adb619ec9eb80507"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Model Evaluation with LazyPredict\n",
    "\"\"\"\n",
    "# %%\n",
    "def evaluate_with_lazypredict(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate multiple regression models using LazyPredict.\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Evaluating models with LazyPredict...\")\n",
    "    \n",
    "    # Initialize LazyRegressor\n",
    "    reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    \n",
    "    # Fit and evaluate models\n",
    "    models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Model Performance Summary:\")\n",
    "    print(models.sort_values('R-Squared', ascending=False))\n",
    "    \n",
    "    # Plot top models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_models = models.sort_values('R-Squared', ascending=False).head(10)\n",
    "    sns.barplot(x='R-Squared', y=top_models.index, data=top_models)\n",
    "    plt.title('Top 10 Models by R-Squared Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return models"
   ],
   "id": "86def289858dfbe8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Main Execution\n",
    "\"\"\"\n",
    "# %%\n",
    "def main():\n",
    "    # Initialize timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"üöÄ Starting product price prediction pipeline with LazyPredict...\")\n",
    "\n",
    "    # 1. Data Loading\n",
    "    print(\"\\nüìÇ Loading data...\")\n",
    "    data_loader = DataLoader(TRAINING_DATA_PATH, TESTING_DATA_PATH)\n",
    "    combined_df = data_loader.get_data()\n",
    "    print(f\"‚úÖ Data loaded. Shape: {combined_df.shape}\")\n",
    "\n",
    "    # 2. Data Preprocessing\n",
    "    print(\"\\nüîß Preprocessing data...\")\n",
    "    preprocessor = DataPreprocessing(combined_df)\n",
    "\n",
    "    # Training/validation split\n",
    "    X_train, X_val, y_train, y_val = preprocessor.preprocess()\n",
    "    print(f\"‚úÖ Training data prepared. Features: {X_train.shape[1]}, Samples: {X_train.shape[0]}\")\n",
    "\n",
    "    # 3. Model Evaluation with LazyPredict\n",
    "    model_performance = evaluate_with_lazypredict(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Get top 3 models\n",
    "    top_models = model_performance.sort_values('R-Squared', ascending=False).head(3).index.tolist()\n",
    "    print(f\"\\nüèÜ Top 3 models: {', '.join(top_models)}\")\n",
    "    \n",
    "    # Pipeline completion\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nüéâ Pipeline completed in {total_time:.2f} seconds!\")\n",
    "    \n",
    "    return model_performance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_results = main()"
   ],
   "id": "837c49a1735b44f0"
  }
 ]
}
